import { main, AudioState } from "./app"
import * as audio from "./audio"
import * as math from "./math"

// Globals for canvas rendering
const canvas = document.querySelector("canvas")
const ctx = canvas.getContext("2d")
let width = window.innerWidth
let height = window.innerHeight

// Store various input/device state generated by events
const mouse = { x: 0, y: 0 }
const orientation = { x: 0, y: 47, z: 0 }

async function init() {
  // Remove the interaction prompt
  document.querySelector("h1").remove()

  // Try to get various permissions
  try {
    DeviceOrientationEvent.requestPermission()
  } catch {}
  try {
    navigator.wakeLock.request("screen")
  } catch {}

  // Run the audio
  const audioAPI = main()

  function tick(ms: number) {
    // Update the audio every frame
    audioAPI.tick(ms, orientation, [])

    ctx.clearRect(0, 0, canvas.width, canvas.height)
    drawSpectrum(audioAPI.state)
    // drawMouse()

    ctx.fillStyle = "#fff"
    ctx.fillText(`Orient: ${orientation.y}`, window.innerWidth / 2, 20)

    requestAnimationFrame(tick)
  }
  requestAnimationFrame(tick)
}

function drawSpectrum(state: AudioState) {
  const nBins = audio.analyser.frequencyBinCount
  const binData = new Uint8Array(nBins)
  audio.analyser.getByteFrequencyData(binData)

  ctx.fillStyle = `lch(80 ${math.denormalized(state.transposition, 20, 200)} ${state.chord * 360})`
  for (let i = 0; i < nBins; i++) {
    let frac = i / nBins
    frac **= 0.5 // This biases the spectrum so that low frequencies are wider, which more closely matches how we perceive pitch
    const x = frac * window.innerWidth
    const y = (1 - binData[i] / 256) * window.innerHeight
    let scale = (30 * state.distortion + (1 - frac) ** 2 + 0.2) * math.denormalized(state.amplitude, 0.5, 2)
    ctx.fillRect(x - 2 * scale, y - 4 * scale, 4 * scale, 8 * scale)
  }
}

function drawMouse() {
  ctx.beginPath()
  ctx.fillStyle = "#fff"
  ctx.arc(mouse.x, mouse.y, 10, 0, math.TAU)
  ctx.fill()
}

// Resize the canvas, set a nice scale factor, and set sensible defaults (which get cleared on resize)
function resize() {
  const dpi = window.devicePixelRatio
  width = window.innerWidth
  height = window.innerHeight
  canvas.width = dpi * width
  canvas.height = dpi * height
  ctx.resetTransform()
  ctx.scale(dpi, dpi)
  ctx.font = "12px sans-serif"
  ctx.textAlign = "center"
  ctx.textBaseline = "middle"
  ctx.lineCap = "round"
  ctx.lineJoin = "round"
}

window.addEventListener("resize", resize)
resize()

// Track the mouse position
window.addEventListener("pointermove", (e) => {
  mouse.x = e.clientX
  mouse.y = e.clientY
})

// When the user clicks, initialize the audio and begin running
window.addEventListener("pointerup", init, { once: true })

window.addEventListener("deviceorientation", (e) => {
  orientation.x = e.gamma // gamma: left to right
  orientation.y = e.beta // beta: front back motion
  orientation.z = e.alpha // alpha: rotation around z-axis
})
