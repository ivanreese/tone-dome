import { main, AudioState } from "./app"
import * as audio from "./audio"
import * as math from "./math"

const runAnalysis = true

// Globals for canvas rendering
const canvas = document.querySelector("canvas")
const ctx = canvas.getContext("2d")
let width = window.innerWidth
let height = window.innerHeight

// Store various input/device state generated by events
const mouse = { x: 0, y: 0, down: false }
const orientation = { x: 0, y: 0, z: 0 }

const inputs = {
  orientation: { x: 0, y: 0, z: 0 },
  oscillators: [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
  flickers: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
  effects: {
    blorpAtMs: 0,
    maxActive: 4,
    doDetune: 0,
    doDistortion: 0,
    doFlicker: 0,
    doExtraNotes: 0,
  },
}

async function init() {
  // Remove the interaction prompt
  document.querySelector("h1").remove()

  try {
    navigator.wakeLock.request("screen")
  } catch {}

  // Run the audio
  const audioAPI = main(runAnalysis)

  function tick(ms: number) {
    if (mouse.down) {
      mouse.down = false
      inputs.effects.blorpAtMs = ms
    }

    // Update the audio every frame
    audioAPI.tick(ms, inputs)

    if (runAnalysis) {
      ctx.clearRect(0, 0, canvas.width, canvas.height)
      drawSpectrum(audioAPI.state)
      // drawMouse()

      audioAPI.state.oscillators.forEach((osc, oscIndex) => {
        addCircle(`osc ${oscIndex} amp`, 1, oscIndex, osc.amplitude)
        addCircle(`osc ${oscIndex} flicker`, 2, oscIndex, osc.flicker)
      })

      audioAPI.state.pois.forEach((poi, poiIndex) => {
        addCircle(`poi ${poiIndex} amp`, 3, poiIndex, poi.amplitude)
        addCircle(`poi ${poiIndex} note`, 4, poiIndex, poi.note)
      })

      addCircle("orientation", 0, 0, orientation.y / 90)
      addCircle("active", 0, 1, audioAPI.state.active)
      addCircle("amplitude", 0, 2, audioAPI.state.amplitude)
      addCircle("chord", 0, 3, audioAPI.state.chord)
      addCircle("detune", 0, 5, audioAPI.state.detune)
      addCircle("distortion", 0, 6, audioAPI.state.distortion)
      addCircle("flicker", 0, 7, audioAPI.state.flicker)
      addCircle("transposition", 0, 8, audioAPI.state.transposition)
      addCircle("chorus", 0, 4, audioAPI.state.chorus) // Chorus goes on top :)
    }

    requestAnimationFrame(tick)
  }
  requestAnimationFrame(tick)
}

function drawSpectrum(state: AudioState) {
  const nBins = audio.analyser.frequencyBinCount
  const binData = new Uint8Array(nBins)
  audio.analyser.getByteFrequencyData(binData)

  const l = math.denormalized(state.flicker, 40, 100)
  const c = math.denormalized(state.transposition, 20, 200)
  const h = state.chord * 360
  ctx.fillStyle = `lch(${l} ${c} ${h})`
  for (let i = 0; i < nBins; i++) {
    let frac = i / nBins
    frac **= 0.5 // This biases the spectrum so that low frequencies are wider, which more closely matches how we perceive pitch
    const x = frac * window.innerWidth
    const y = (1 - binData[i] / 256) * window.innerHeight
    let scale = (5 * state.distortion + (1 - frac) ** 2 + 0.2) * math.denormalized(state.amplitude, 0.5, 2)
    ctx.fillRect(x - 2 * scale, y - 4 * scale, 4 * scale, 8 * scale)
  }
}

function addCircle(name: string, x: number, y: number, size: number) {
  ctx.beginPath()
  ctx.fillStyle = "#0002"
  ctx.arc(25 + x * 150, 25 + y * 45, 20, 0, math.TAU)
  ctx.fill()
  ctx.beginPath()
  ctx.fillStyle = "#fff"
  ctx.arc(25 + x * 150, 25 + y * 45, Math.max(0, 20 * size), 0, math.TAU)
  ctx.fill()
  ctx.fillText(name, 50 + x * 150, 25 + y * 45)
}

function drawMouse() {
  ctx.beginPath()
  ctx.fillStyle = "#fff"
  ctx.arc(mouse.x, mouse.y, 10, 0, math.TAU)
  ctx.fill()
}

// Resize the canvas, set a nice scale factor, and set sensible defaults (which get cleared on resize)
function resize() {
  const dpi = window.devicePixelRatio
  width = window.innerWidth
  height = window.innerHeight
  canvas.width = dpi * width
  canvas.height = dpi * height
  ctx.resetTransform()
  ctx.scale(dpi, dpi)
  ctx.font = "12px sans-serif"
  ctx.textAlign = "left"
  ctx.textBaseline = "middle"
  ctx.lineCap = "round"
  ctx.lineJoin = "round"
}

window.addEventListener("resize", resize)
resize()

// Track the mouse position
window.addEventListener("pointermove", (e) => {
  mouse.x = e.clientX
  mouse.y = e.clientY
})

window.addEventListener("pointerdown", (e) => {
  mouse.down = true
})
window.addEventListener("pointerup", (e) => {
  mouse.down = false
})

// When the user clicks, initialize the audio and begin running
window.addEventListener("pointerup", init, { once: true })
